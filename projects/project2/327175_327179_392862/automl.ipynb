{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2c8bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler,FunctionTransformer\n",
    "from sklearn.compose import make_column_transformer, make_column_selector, ColumnTransformer\n",
    "\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, roc_auc_score, roc_curve, balanced_accuracy_score, mean_squared_error, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ced85e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mean(x: np.array, theta: float) -> float:\n",
    "    return np.mean(x) - theta * np.std(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "864a03d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top10(topk, all_models): # zmieniamy by miec wektor 50 wymiarowy 0 i 1\n",
    "    return np.array([1 if m in topk else 0 for m in all_models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30a319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import importlib\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "class MiniAutoML:\n",
    "\n",
    "    def __init__(self, models_config, theta=0.25):\n",
    "        self.models_config = models_config\n",
    "        self.models = []\n",
    "        self.models_best = None\n",
    "        self.models_load()\n",
    "        self.models_build()\n",
    "        self.theta = theta\n",
    "        self.skew_pos_data = None\n",
    "        self.skew_neg_data = None\n",
    "\n",
    "\n",
    "    def models_load(self):\n",
    "        with open(self.models_config, 'r') as file:\n",
    "            self.cfg= json.load(file)\n",
    "    def models_build(self):\n",
    "        numerical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy = 'median')),\n",
    "            ('scaler', StandardScaler())\n",
    "                ])\n",
    "        categorical_transformer = Pipeline(steps = [\n",
    "            ('imputer', SimpleImputer(strategy = 'most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown = 'ignore',sparse_output=False))\n",
    "            ])\n",
    "        preprocessor = ColumnTransformer([\n",
    "            ('numerical', numerical_transformer, make_column_selector(dtype_include=np.number)),\n",
    "            ('categorical', categorical_transformer, make_column_selector(dtype_include=np.object_))\n",
    "            ])\n",
    "\n",
    "        for m in self.cfg:\n",
    "            name = m.get('name')\n",
    "            module_name, class_name = m.get('class').rsplit(\".\", 1)\n",
    "            module = importlib.import_module(module_name)\n",
    "            Class = getattr(module, class_name)\n",
    "            params = m.get('params',{})\n",
    "            model = Pipeline([\n",
    "                ('pre', preprocessor),\n",
    "                (name, Class(**params))\n",
    "            ])\n",
    "            self.models.append((name, model, class_name))\n",
    "\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        meta_df = pd.read_csv(\"meta_dataset.csv\")\n",
    "        y = np.vstack([top10(t, [m.get('name') for m in self.cfg]) for t in meta_df[\"top10_models\"]])\n",
    "        X = meta_df.drop(columns=[\"top10_models\"])\n",
    "        knn= Pipeline([\n",
    "            ('scaler',StandardScaler()),\n",
    "            ('knn',KNeighborsClassifier(n_neighbors=3))\n",
    "        ])\n",
    "        knn.fit(X,y)\n",
    "\n",
    "        X_train= pd.DataFrame(X_train)\n",
    "        y_train = pd.Series(y_train)\n",
    "        selector = make_column_selector(dtype_include=['object', 'category'])\n",
    "        selected_cols = selector(X_train)\n",
    "        p=np.mean(y_train==y_train.unique()[1])\n",
    "\n",
    "        X_new = pd.DataFrame([{\n",
    "            'n_features':X_train.shape[1],\n",
    "            \"n_samples\": X_train.shape[0],\n",
    "            \"class_imbalance\":  min(1-p,p),\n",
    "            'n_skew_pos':len(list(X_train.drop(selected_cols,axis=1).loc[:, X_train.skew(numeric_only=True) > 1].dtypes.index)),\n",
    "            'n_skew_neg':len(list(X_train.drop(selected_cols,axis=1).loc[:, X_train.skew(numeric_only=True) < - 1].dtypes.index))\n",
    "            }])\n",
    "        probs = []\n",
    "        proba = knn.predict_proba(X_new)\n",
    "        for i, p in enumerate(proba):\n",
    "          classes = knn.named_steps[\"knn\"].classes_[i]\n",
    "          if len(classes) == 2:\n",
    "            prob = p[0, 1]\n",
    "          else:\n",
    "            prob = 1.0 if classes[0] == 1 else 0.0\n",
    "          probs.append(prob)\n",
    "\n",
    "        probs = np.array(probs)\n",
    "        top5_idx = np.argsort(probs)[-5:][::-1]\n",
    "        top5_models_new = [ [m.get('name') for m in self.cfg][i] for i in top5_idx]\n",
    "        X_train_new = X_train\n",
    "        print(top5_models_new)\n",
    "        # sprawdzamy czy istnieja cechy ktore sa istotnie skosne, jesli tak to logarytmujemy\n",
    "        self.skew_neg_data=list(X_train.drop(selected_cols,axis=1).loc[:, X_train.skew(numeric_only=True) < -1].dtypes.index)\n",
    "        if len(self.skew_neg_data)>0:\n",
    "          X_train_new[self.skew_neg_data] = np.log1p(np.max(X_train[self.skew_neg_data])-X_train[self.skew_neg_data])\n",
    "        self.skew_pos_data=list(X_train.drop(selected_cols,axis=1).loc[:, X_train.skew(numeric_only=True) > 1].dtypes.index)\n",
    "        if len(self.skew_pos_data)>0:\n",
    "          X_train_new[self.skew_pos_data] = np.log1p(X_train[self.skew_pos_data])\n",
    "\n",
    "\n",
    "        score = []\n",
    "        for name, model, class_name in self.models:\n",
    "            if X_train.shape[1] > 20 and class_name == \"LogisticRegression\": # za duzo zmiennych regresja logistyczna liczy sie za dlugo...\n",
    "              score.append(0)\n",
    "            else:\n",
    "              if name in top5_models_new:\n",
    "                scr = cross_val_score(model, X_train_new, y_train, cv=3, scoring='balanced_accuracy')\n",
    "                score.append(weighted_mean(scr, self.theta))\n",
    "                # metryka stabilnosci? Chcemy by stablnosc modelu rowniez miala znaczenie w rozwanaiu modelu, parametrem theta bedziemy decydowac jak duzy to wplyw\n",
    "                print(f\"{name}: score = {weighted_mean(scr, self.theta):.4f}\")\n",
    "              else:\n",
    "                score.append(0)\n",
    "        score_np = np.array(score)\n",
    "        idx = np.argsort(score_np)[-3:][::-1]\n",
    "        est = [(self.models[i][0],self.models[i][1]) for i in idx]\n",
    "\n",
    "        # --------------------------- VOTING -----------------------------------\n",
    "        Voting = Pipeline([\n",
    "                ('voting', VotingClassifier(estimators=est))\n",
    "            ])\n",
    "        self.models.append(('voting', Voting, 'VotingClassifier'))\n",
    "        scr=cross_val_score(Voting, X_train_new, y_train, cv=3, scoring='balanced_accuracy')\n",
    "        score.append(weighted_mean(scr, self.theta))\n",
    "        print(f\"Voting: score = {weighted_mean(scr, self.theta):.4f}\")\n",
    "\n",
    "        # --------------------------- STACKING ---------------------------------\n",
    "        Stacking = Pipeline([\n",
    "                ('stacking', StackingClassifier(estimators=est))\n",
    "            ])\n",
    "        self.models.append(('stacking', Stacking, 'StackingClassifier'))\n",
    "        scr=cross_val_score(Stacking, X_train_new, y_train, cv=3, scoring='balanced_accuracy')\n",
    "        score.append(weighted_mean(scr, self.theta))\n",
    "        print(f\"Stacking: score = {weighted_mean(scr, self.theta):.4f}\")\n",
    "\n",
    "\n",
    "        for name, model,_ in self.models:\n",
    "              model.fit(X_train_new, y_train)\n",
    "        name, self.models_best, _ = self.models[np.argmax(score)]\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_test= pd.DataFrame(X_test)\n",
    "        X_test_new = X_test\n",
    "        if len(self.skew_neg_data)>0:\n",
    "          X_test_new[self.skew_neg_data] = np.log1p(np.max(X_test[self.skew_neg_data])-X_test[self.skew_neg_data])\n",
    "        if len(self.skew_pos_data)>0:\n",
    "          X_test_new[self.skew_pos_data] = np.log1p(X_test[self.skew_pos_data])\n",
    "\n",
    "        return self.models_best.predict(X_test_new)\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        X_test = pd.DataFrame(X_test)\n",
    "        X_test_new = X_test\n",
    "        if len(self.skew_neg_data)>0:\n",
    "          X_test_new[self.skew_neg_data] = np.log1p(np.max(X_test[self.skew_neg_data])-X_test[self.skew_neg_data])\n",
    "        if len(self.skew_pos_data)>0:\n",
    "          X_test_new[self.skew_pos_data] = np.log1p(X_test[self.skew_pos_data])\n",
    "\n",
    "        return self.models_best.predict_proba(X_test_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
