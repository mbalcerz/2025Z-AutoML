{
 "cells": [
  {
   "cell_type": "code",
   "id": "3a1c4721-1200-4d6d-97fe-b940d0f2f533",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T10:50:24.722427Z",
     "start_time": "2026-01-26T10:50:24.713177Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "# Import Twojej klasy\n",
    "from mini_auto_ml import MiniAutoML"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "f0b940f7-8527-41e5-a762-43fa91dd9f4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T10:50:24.816037Z",
     "start_time": "2026-01-26T10:50:24.761467Z"
    }
   },
   "source": [
    "# ==================================================\n",
    "# 1. Wczytanie danych\n",
    "# ==================================================\n",
    "\n",
    "X = pd.read_csv('../Datasets/X.csv')\n",
    "y = pd.read_csv('../Datasets/y.csv')\n",
    "\n",
    "# Jeśli y wczytało się jako DataFrame (1 kolumna), zamieniamy na Series\n",
    "if isinstance(y, pd.DataFrame):\n",
    "    y = y.iloc[:, 0]\n",
    "\n",
    "print(f\"Dane wczytane: X={X.shape}, y={y.shape}\")\n",
    "\n",
    "\n",
    "# Podział Train/Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dane wczytane: X=(3481, 16), y=(3481,)\n",
      "Train: (2784, 16), Test: (697, 16)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "0b4fd2c5-7bf7-4925-9f5d-eb8453c43dae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T10:50:24.833493Z",
     "start_time": "2026-01-26T10:50:24.822277Z"
    }
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "7ab4f7226557d14a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T10:53:34.416808Z",
     "start_time": "2026-01-26T10:50:24.867935Z"
    }
   },
   "source": [
    "\n",
    "# ==================================================\n",
    "# 2. Uruchomienie MiniAutoML\n",
    "# ==================================================\n",
    "\n",
    "mini = MiniAutoML(\n",
    "    time_budget=30,       # Czas na szukanie modeli (np. 120s)\n",
    "    cv_folds=5,            # Walidacja krzyżowa\n",
    "    task='classification', # Ważne: typ zadania\n",
    "    method='xgboost'       # Metoda selekcji cech\n",
    "    ,final_estimator=LogisticRegression(random_state=42, penalty='l2', C=0.1)\n",
    "    ,ensemble_type='pseudo_autogluon'\n",
    ")\n",
    "\n",
    "# A. FIT: Preprocessing -> Feature Selection -> Szukanie Modeli -> Refit\n",
    "result = mini.fit(X_train, y_train)\n",
    "\n",
    "# Sprawdzenie, jakie modele zostały wybrane\n",
    "print(\"\\n>>> Wybrane modele (Baza do stackingu):\")\n",
    "if hasattr(mini, 'final_models'):\n",
    "    for i, m in enumerate(mini.final_models):\n",
    "        print(f\"   {i+1}. {m.__class__.__name__}\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 11:50:25,749] A new study created in memory with name: no-name-801d9012-aa76-4152-8117-1dfbb7191bbd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MiniAutoML] Krok 3: Szukanie Modeli (Budżet: 30s)...\n",
      "[Sanitizer] Czyszczenie danych dla CatBoosta (klucz: 'cat_not_enc')...\n",
      "[Etap 1: Hyperband] Start. Budżet: 12.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 11:50:26,180] Trial 5 finished with value: -0.6957063127243088 and parameters: {'config_name': 'LogisticRegression_5'}. Best is trial 5 with value: -0.6957063127243088.\n",
      "[I 2026-01-26 11:50:26,196] Trial 9 finished with value: -0.6957063127243088 and parameters: {'config_name': 'LogisticRegression_5'}. Best is trial 5 with value: -0.6957063127243088.\n",
      "[I 2026-01-26 11:50:27,314] Trial 4 pruned. \n",
      "[I 2026-01-26 11:50:27,362] Trial 13 pruned. \n",
      "[I 2026-01-26 11:50:27,831] Trial 7 pruned. \n",
      "[I 2026-01-26 11:50:27,869] Trial 8 finished with value: -0.6926335162386557 and parameters: {'config_name': 'LightGBM_6'}. Best is trial 8 with value: -0.6926335162386557.\n",
      "[I 2026-01-26 11:50:27,869] Trial 11 finished with value: -0.6926335162386557 and parameters: {'config_name': 'LightGBM_6'}. Best is trial 8 with value: -0.6926335162386557.\n",
      "[I 2026-01-26 11:50:27,883] Trial 1 finished with value: -0.6934823618289329 and parameters: {'config_name': 'LightGBM_4'}. Best is trial 8 with value: -0.6926335162386557.\n",
      "[I 2026-01-26 11:50:28,115] Trial 2 pruned. \n",
      "[I 2026-01-26 11:50:28,156] Trial 14 pruned. \n",
      "[I 2026-01-26 11:50:28,384] Trial 19 pruned. \n",
      "[I 2026-01-26 11:50:29,680] Trial 10 pruned. \n",
      "[I 2026-01-26 11:50:29,802] Trial 23 pruned. \n",
      "[I 2026-01-26 11:50:31,508] Trial 20 pruned. \n",
      "[I 2026-01-26 11:50:32,145] Trial 16 pruned. \n",
      "[I 2026-01-26 11:50:32,540] Trial 3 finished with value: -0.6927565880019194 and parameters: {'config_name': 'XGBoost_7'}. Best is trial 8 with value: -0.6926335162386557.\n",
      "[I 2026-01-26 11:50:38,425] Trial 0 pruned. \n",
      "[I 2026-01-26 11:50:39,122] Trial 22 pruned. \n",
      "[I 2026-01-26 11:50:46,163] Trial 12 pruned. \n",
      "[I 2026-01-26 11:51:01,526] Trial 27 pruned. \n",
      "[I 2026-01-26 11:51:08,481] Trial 6 pruned. \n",
      "[I 2026-01-26 11:51:11,606] Trial 24 pruned. \n",
      "[I 2026-01-26 11:51:12,995] Trial 21 pruned. \n",
      "[I 2026-01-26 11:52:38,769] Trial 15 pruned. \n",
      "[I 2026-01-26 11:52:39,879] Trial 18 pruned. \n",
      "[I 2026-01-26 11:52:40,051] Trial 17 pruned. \n",
      "[I 2026-01-26 11:52:40,094] Trial 26 pruned. \n",
      "[I 2026-01-26 11:52:52,125] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Etap 2: Full CV] Weryfikacja 4 modeli.\n",
      "[Etap 2] Selekcja finałowa:\n",
      " Akceptacja: LightGBM_6 (Grupa: fast_boostings) -> Score: 0.5321\n",
      " Akceptacja: LogisticRegression_5 (Grupa: simple_models) -> Score: 0.5317\n",
      " Akceptacja: XGBoost_7 (Grupa: fast_boostings) -> Score: 0.5041\n",
      "[Etap 3: Greedy] Start. Kandydaci: 3. Limit: -129.28s\n",
      "[Etap 3] Koniec. Wybrano 3 modeli.\n",
      "[ModelSelector] Koniec procesu. Wybrano 3 modeli.\n",
      "[MiniAutoML] Krok 4: Refit (3 modeli)...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 15\u001B[39m\n\u001B[32m      5\u001B[39m mini = MiniAutoML(\n\u001B[32m      6\u001B[39m     time_budget=\u001B[32m30\u001B[39m,       \u001B[38;5;66;03m# Czas na szukanie modeli (np. 120s)\u001B[39;00m\n\u001B[32m      7\u001B[39m     cv_folds=\u001B[32m5\u001B[39m,            \u001B[38;5;66;03m# Walidacja krzyżowa\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     11\u001B[39m     ,ensemble_type=\u001B[33m'\u001B[39m\u001B[33mpseudo_autogluon\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m     12\u001B[39m )\n\u001B[32m     14\u001B[39m \u001B[38;5;66;03m# A. FIT: Preprocessing -> Feature Selection -> Szukanie Modeli -> Refit\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m result = \u001B[43mmini\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     17\u001B[39m \u001B[38;5;66;03m# Sprawdzenie, jakie modele zostały wybrane\u001B[39;00m\n\u001B[32m     18\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m>>> Wybrane modele (Baza do stackingu):\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\AutoML\\Mini_AutoML\\src\\mini_auto_ml.py:720\u001B[39m, in \u001B[36mMiniAutoML.fit\u001B[39m\u001B[34m(self, X_train, y_train)\u001B[39m\n\u001B[32m    718\u001B[39m     n_models = \u001B[38;5;28msum\u001B[39m(\u001B[38;5;28mlen\u001B[39m(layer) \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m layers_estimators)\n\u001B[32m    719\u001B[39m     data_frames = [data_frames[\u001B[32m0\u001B[39m]] * n_models\n\u001B[32m--> \u001B[39m\u001B[32m720\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel_\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_frames\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    722\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    723\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    724\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mInvalid ensemble_type: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.ensemble_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    725\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\AutoML\\Mini_AutoML\\src\\ensemble\\pseudo_auto_gluon.py:179\u001B[39m, in \u001B[36mPseudoAutoGluon.fit\u001B[39m\u001B[34m(self, X_list, y)\u001B[39m\n\u001B[32m    176\u001B[39m     X_val = np.hstack([X_val, stacked_features[val]])\n\u001B[32m    178\u001B[39m m = clone(model)\n\u001B[32m--> \u001B[39m\u001B[32m179\u001B[39m \u001B[43mm\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_tr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_tr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    181\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.task == \u001B[33m\"\u001B[39m\u001B[33mclassification\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    182\u001B[39m     p = m.predict_proba(X_val)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\AutoML\\Mini_AutoML\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1382\u001B[39m     estimator._validate_params()\n\u001B[32m   1384\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1385\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1386\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1387\u001B[39m     )\n\u001B[32m   1388\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1389\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\AutoML\\Mini_AutoML\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1222\u001B[39m, in \u001B[36mLogisticRegression.fit\u001B[39m\u001B[34m(self, X, y, sample_weight)\u001B[39m\n\u001B[32m   1219\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1220\u001B[39m     _dtype = [np.float64, np.float32]\n\u001B[32m-> \u001B[39m\u001B[32m1222\u001B[39m X, y = \u001B[43mvalidate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1223\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1224\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1225\u001B[39m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1226\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcsr\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1227\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43m_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1228\u001B[39m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mC\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1229\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m=\u001B[49m\u001B[43msolver\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mliblinear\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43msag\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43msaga\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1230\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1231\u001B[39m check_classification_targets(y)\n\u001B[32m   1232\u001B[39m \u001B[38;5;28mself\u001B[39m.classes_ = np.unique(y)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\AutoML\\Mini_AutoML\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2961\u001B[39m, in \u001B[36mvalidate_data\u001B[39m\u001B[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001B[39m\n\u001B[32m   2959\u001B[39m         y = check_array(y, input_name=\u001B[33m\"\u001B[39m\u001B[33my\u001B[39m\u001B[33m\"\u001B[39m, **check_y_params)\n\u001B[32m   2960\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2961\u001B[39m         X, y = \u001B[43mcheck_X_y\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2962\u001B[39m     out = X, y\n\u001B[32m   2964\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params.get(\u001B[33m\"\u001B[39m\u001B[33mensure_2d\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\AutoML\\Mini_AutoML\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1370\u001B[39m, in \u001B[36mcheck_X_y\u001B[39m\u001B[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[39m\n\u001B[32m   1364\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1365\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m requires y to be passed, but the target y is None\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1366\u001B[39m     )\n\u001B[32m   1368\u001B[39m ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001B[32m-> \u001B[39m\u001B[32m1370\u001B[39m X = \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1371\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1372\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[43m=\u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1373\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m=\u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1374\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1375\u001B[39m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[43m=\u001B[49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1376\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1377\u001B[39m \u001B[43m    \u001B[49m\u001B[43mforce_writeable\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_writeable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1378\u001B[39m \u001B[43m    \u001B[49m\u001B[43mensure_all_finite\u001B[49m\u001B[43m=\u001B[49m\u001B[43mensure_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1379\u001B[39m \u001B[43m    \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[43m=\u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1380\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_nd\u001B[49m\u001B[43m=\u001B[49m\u001B[43mallow_nd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1381\u001B[39m \u001B[43m    \u001B[49m\u001B[43mensure_min_samples\u001B[49m\u001B[43m=\u001B[49m\u001B[43mensure_min_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1382\u001B[39m \u001B[43m    \u001B[49m\u001B[43mensure_min_features\u001B[49m\u001B[43m=\u001B[49m\u001B[43mensure_min_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1383\u001B[39m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m=\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1384\u001B[39m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mX\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1385\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1387\u001B[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001B[32m   1389\u001B[39m check_consistent_length(X, y)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\AutoML\\Mini_AutoML\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1107\u001B[39m, in \u001B[36mcheck_array\u001B[39m\u001B[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[39m\n\u001B[32m   1101\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1102\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[33m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m expected <= 2.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1103\u001B[39m         % (array.ndim, estimator_name)\n\u001B[32m   1104\u001B[39m     )\n\u001B[32m   1106\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m ensure_all_finite:\n\u001B[32m-> \u001B[39m\u001B[32m1107\u001B[39m     \u001B[43m_assert_all_finite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1108\u001B[39m \u001B[43m        \u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1109\u001B[39m \u001B[43m        \u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1110\u001B[39m \u001B[43m        \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1111\u001B[39m \u001B[43m        \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[43m=\u001B[49m\u001B[43mensure_all_finite\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mallow-nan\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1112\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1114\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m copy:\n\u001B[32m   1115\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m _is_numpy_namespace(xp):\n\u001B[32m   1116\u001B[39m         \u001B[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\AutoML\\Mini_AutoML\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001B[39m, in \u001B[36m_assert_all_finite\u001B[39m\u001B[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[39m\n\u001B[32m    117\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m first_pass_isfinite:\n\u001B[32m    118\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m120\u001B[39m \u001B[43m_assert_all_finite_element_wise\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    121\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    122\u001B[39m \u001B[43m    \u001B[49m\u001B[43mxp\u001B[49m\u001B[43m=\u001B[49m\u001B[43mxp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    123\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[43m=\u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    124\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmsg_dtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmsg_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    125\u001B[39m \u001B[43m    \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    126\u001B[39m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    127\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\AutoML\\Mini_AutoML\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001B[39m, in \u001B[36m_assert_all_finite_element_wise\u001B[39m\u001B[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001B[39m\n\u001B[32m    152\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name == \u001B[33m\"\u001B[39m\u001B[33mX\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[32m    153\u001B[39m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[32m    154\u001B[39m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[32m    155\u001B[39m     msg_err += (\n\u001B[32m    156\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m does not accept missing values\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    157\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   (...)\u001B[39m\u001B[32m    167\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m#estimators-that-handle-nan-values\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    168\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m169\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
      "\u001B[31mValueError\u001B[39m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32d7b7d0c5475cca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T10:53:34.462204200Z",
     "start_time": "2026-01-25T01:02:21.525966Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mini_auto_ml.MiniAutoML at 0x1dd435bb910>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22aad790-7c16-4cc7-ab6d-24a6d12b3788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6954022988505747)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mini.predict(X_train) == y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed692bdee2d874c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T10:53:34.477935100Z",
     "start_time": "2026-01-25T01:03:23.456282Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = mini.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8becfee3-4c1d-4e63-8534-c3d7f9c80bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5710186513629842)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fa9658c4400c9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T10:53:34.493486900Z",
     "start_time": "2026-01-25T01:03:23.904515Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_probas = mini.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cee9c07-60a8-4402-8d8c-ab188a778433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7f885a7-5f3a-484c-b14f-5c04e11b0e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5771344845284019)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true=y_test, y_score=y_pred_probas[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c55c6f798fb76d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T10:53:34.493486900Z",
     "start_time": "2026-01-25T00:34:55.127924Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_true=y_test, y_score=y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
