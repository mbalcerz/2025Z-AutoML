{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22e369ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from operator import itemgetter\n",
    "import json\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class MiniAutoML:\n",
    "    def __init__(self, models_path, n_jobs=1, voting=False):\n",
    "        with open(models_path, 'r') as f:\n",
    "            self.models_config = json.load(f)\n",
    "        self.best_model_pipeline = None\n",
    "        self.best_score = -1\n",
    "        self.results = []\n",
    "        self.n_jobs = n_jobs\n",
    "        self.voting = voting\n",
    "\n",
    "    def _get_clf_class(self, class_string):\n",
    "        module_name, class_name = class_string.rsplit('.', 1)\n",
    "        module = importlib.import_module(module_name)\n",
    "        return getattr(module, class_name)\n",
    "\n",
    "    def _create_preprocessing_pipeline(self, X):\n",
    "        numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "        categorical_features = X.select_dtypes(include=['object', 'bool', 'category']).columns\n",
    "\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "        ])\n",
    "\n",
    "        return ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', numeric_transformer, numeric_features),\n",
    "                ('cat', categorical_transformer, categorical_features)\n",
    "            ])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        preprocessor = self._create_preprocessing_pipeline(X)\n",
    "        self.results = [] \n",
    "        \n",
    "        for i, model_entry in enumerate(self.models_config):\n",
    "\n",
    "            name = model_entry['name']\n",
    "            clf_class = self._get_clf_class(model_entry['class'])\n",
    "            params = model_entry['params'].copy()\n",
    "            \n",
    "            # Poprawki parametrów\n",
    "            if 'HistGradientBoosting' in model_entry['class'] and params.get('loss') == 'auto':\n",
    "                params['loss'] = 'log_loss'\n",
    "            \n",
    "            tree_based_models = ['RandomForest', 'ExtraTrees', 'DecisionTree']\n",
    "            if any(tree_model in model_entry['class'] for tree_model in tree_based_models):\n",
    "                if 'min_impurity_split' in params: del params['min_impurity_split']\n",
    "                if 'tol' in params: del params['tol']\n",
    "                if params.get('max_features') == 'auto': params['max_features'] = 'sqrt'\n",
    "\n",
    "            clf = clf_class(**params)\n",
    "            \n",
    "            temp_pipeline = Pipeline(steps=[\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('classifier', clf)\n",
    "            ])\n",
    "            \n",
    "            try:\n",
    "                scores = cross_val_score(temp_pipeline, X, y, cv=5, scoring='balanced_accuracy', n_jobs = self.n_jobs)\n",
    "                mean_score = np.mean(scores)\n",
    "                \n",
    "                self.results.append({\n",
    "                    'name': name,\n",
    "                    'score': mean_score,\n",
    "                    'clf': clf \n",
    "                })\n",
    "                \n",
    "                print(f\" {i+1}/{len(self.models_config)} Model: {name} | Średnie Balanced Accuracy: {mean_score:.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Błąd przy modelu {name}: {e}\")\n",
    "\n",
    "        if not self.results:\n",
    "            raise ValueError(\"Nie udało się wytrenować żadnego modelu.\")\n",
    "\n",
    "\n",
    "        if self.voting and len(self.results) >= 5:\n",
    "            self.results.sort(key=itemgetter('score'), reverse=True)\n",
    "            best_single = self.results[0]\n",
    "\n",
    "            top_5_results = self.results[:5]\n",
    "            estimators = [(res['name'], res['clf']) for res in top_5_results]\n",
    "            voting_clf = VotingClassifier(estimators=estimators, voting='soft', n_jobs = self.n_jobs)\n",
    "            \n",
    "            voting_pipeline = Pipeline(steps=[\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('classifier', voting_clf)\n",
    "            ])\n",
    "\n",
    "            print(f\"\\n Porównanie najlepszego dotychczas modelu z VotingClassifier z najlepszych 5 modeli:\")\n",
    "            \n",
    "            try:\n",
    "                v_scores = cross_val_score(voting_pipeline, X, y, cv=5, scoring='balanced_accuracy', n_jobs = self.n_jobs)\n",
    "                v_score = np.mean(v_scores)\n",
    "                \n",
    "                print(f\" Wynik Voting: {v_score:.4f}\")\n",
    "                print(f\" Wynik Najlepszego Pojedynczego Modelu ({best_single['name']}): {best_single['score']:.4f}\")\n",
    "\n",
    "                if v_score > best_single['score']:\n",
    "                    print(\"Wybrano VotingClassifier.\")\n",
    "                    self.best_model_pipeline = voting_pipeline\n",
    "                    self.best_score = v_score\n",
    "                else:\n",
    "                    print(f\"Pozostawiono pojedynczy model: {best_single['name']}\")\n",
    "                    self.best_model_pipeline = Pipeline(steps=[\n",
    "                        ('preprocessor', preprocessor),\n",
    "                        ('classifier', best_single['clf'])\n",
    "                    ])\n",
    "                    self.best_score = best_single['score']\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\" Błąd przy ocenie Votinga: {e}. Wybieram najlepszy model.\")\n",
    "                self.best_model_pipeline = Pipeline(steps=[\n",
    "                    ('preprocessor', preprocessor),\n",
    "                    ('classifier', best_single['clf'])\n",
    "                ])\n",
    "                self.best_score = best_single['score']\n",
    "\n",
    "        self.best_model_pipeline.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.best_model_pipeline is None:\n",
    "            raise ValueError(\"Model nie został jeszcze dopasowany.\")\n",
    "        return self.best_model_pipeline.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if self.best_model_pipeline is None:\n",
    "            raise ValueError(\"Model nie został jeszcze dopasowany.\")\n",
    "        if not hasattr(self.best_model_pipeline.named_steps['classifier'], 'predict_proba'):\n",
    "            raise ValueError(f\"Wybrany model {self.best_model_pipeline.named_steps['classifier'].__class__.__name__} nie obsługuje predict_proba.\")\n",
    "        return self.best_model_pipeline.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "108ea825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/34 Model: kr_vs_kp_HistGradientBoostingClassifier | Średnie Balanced Accuracy: 0.5308\n",
      " 2/34 Model: credit_approval_HistGradientBoostingClassifier | Średnie Balanced Accuracy: 0.5606\n",
      " 3/34 Model: credit_g_RandomForestClassifier | Średnie Balanced Accuracy: 0.5540\n",
      " 4/34 Model: diabetes_RandomForestClassifier | Średnie Balanced Accuracy: 0.5496\n",
      " 5/34 Model: spambase_RandomForestClassifier | Średnie Balanced Accuracy: 0.5544\n",
      " 6/34 Model: tic_tac_toe_RandomForestClassifier | Średnie Balanced Accuracy: 0.5536\n",
      " 7/34 Model: electricity_HistGradientBoostingClassifier | Średnie Balanced Accuracy: 0.5552\n",
      " 8/34 Model: sick_RandomForestClassifier | Średnie Balanced Accuracy: 0.5369\n",
      " 9/34 Model: pc4_RandomForestClassifier | Średnie Balanced Accuracy: 0.5517\n",
      " 10/34 Model: pc3_RandomForestClassifier | Średnie Balanced Accuracy: 0.5639\n",
      " 11/34 Model: jm1_HistGradientBoostingClassifier | Średnie Balanced Accuracy: 0.5538\n",
      " 12/34 Model: kc2_RandomForestClassifier | Średnie Balanced Accuracy: 0.5593\n",
      " 13/34 Model: kc1_RandomForestClassifier | Średnie Balanced Accuracy: 0.5529\n",
      " 14/34 Model: pc1_RandomForestClassifier | Średnie Balanced Accuracy: 0.5540\n",
      " 15/34 Model: adult_HistGradientBoostingClassifier | Średnie Balanced Accuracy: 0.5454\n",
      " 16/34 Model: Bioresponse_RandomForestClassifier | Średnie Balanced Accuracy: 0.5510\n",
      " 17/34 Model: wdbc_MLPClassifier | Średnie Balanced Accuracy: 0.5531\n",
      " 18/34 Model: phoneme_RandomForestClassifier | Średnie Balanced Accuracy: 0.5567\n",
      " 19/34 Model: qsar_biodeg_RandomForestClassifier | Średnie Balanced Accuracy: 0.5504\n",
      " 20/34 Model: ilpd_RandomForestClassifier | Średnie Balanced Accuracy: 0.5591\n",
      " 21/34 Model: madelon_RandomForestClassifier | Średnie Balanced Accuracy: 0.5579\n",
      " 22/34 Model: nomao_RandomForestClassifier | Średnie Balanced Accuracy: 0.5516\n",
      " 23/34 Model: ozone_level_8hr_RandomForestClassifier | Średnie Balanced Accuracy: 0.5601\n",
      " 24/34 Model: banknote_authentication_SVC | Średnie Balanced Accuracy: 0.5485\n",
      " 25/34 Model: blood_transfusion_service_center_SVC | Średnie Balanced Accuracy: 0.5580\n",
      " 26/34 Model: PhishingWebsites_RandomForestClassifier | Średnie Balanced Accuracy: 0.5460\n",
      " 27/34 Model: cylinder_bands_RandomForestClassifier | Średnie Balanced Accuracy: 0.5400\n",
      " 28/34 Model: bank_marketing_HistGradientBoostingClassifier | Średnie Balanced Accuracy: 0.5507\n",
      " 29/34 Model: dresses_sales_RandomForestClassifier | Średnie Balanced Accuracy: 0.5422\n",
      " 30/34 Model: climate_model_simulation_crashes_RandomForestClassifier | Średnie Balanced Accuracy: 0.5553\n",
      " 31/34 Model: wilt_RandomForestClassifier | Średnie Balanced Accuracy: 0.5392\n",
      " 32/34 Model: numerai28_6_HistGradientBoostingClassifier | Średnie Balanced Accuracy: 0.5534\n",
      " 33/34 Model: Internet_Advertisements_RandomForestClassifier | Średnie Balanced Accuracy: 0.5462\n",
      " 34/34 Model: churn_HistGradientBoostingClassifier | Średnie Balanced Accuracy: 0.5512\n",
      "\n",
      " Porównanie najlepszego dotychczas modelu z VotingClassifier z najlepszych 5 modeli:\n",
      " Wynik Voting: 0.5580\n",
      " Wynik Najlepszego Pojedynczego Modelu (pc3_RandomForestClassifier): 0.5639\n",
      "Pozostawiono pojedynczy model: pc3_RandomForestClassifier\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('X.csv')\n",
    "y = pd.read_csv('y.csv').values.ravel()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "selector = MiniAutoML('models.json', voting=True, n_jobs=-1)\n",
    "selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e219564f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność na zbiorze testowym: 0.5624\n",
      "ROC AUC Score: 0.5803\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "selector.predict(X_test)\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, selector.predict(X_test))\n",
    "print(f\"Dokładność na zbiorze testowym: {balanced_accuracy:.4f}\")\n",
    "\n",
    "probs = selector.predict_proba(X_test)\n",
    "probs_positive = probs[:, 1]\n",
    "auc_score = roc_auc_score(y_test, probs_positive)\n",
    "print(f\"ROC AUC Score: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a434976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
